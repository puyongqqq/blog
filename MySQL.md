### MySQL基础总结

#### 1. MyISAM 和 InnoDB的区别

|           | MyISAM                                   | InnoDB                |
| --------- | ---------------------------------------- | --------------------- |
| 事务      | 不支持                                   | 支持                  |
| 外键      | 不支持                                   | 支持                  |
| 索引类型  | 非聚集索引                               | 聚集索引              |
| 锁粒度    | 表锁                                     | 行锁                  |
| count函数 | 会给每张表维护一个count字段（不加where） | 慢（全表扫描）        |
| 其他      | 5.5之前默认存储引擎                      | 5.5之后的默认存储引擎 |

MyISAM常作为`SELECT`较多时的一种数据库存储引擎，不支持事务，不支持外键，非聚集索引，内部会为维护表的一个count值。每张表在磁盘上存储成三个文件。`.frm`文件存储表定义，`.myd`文件存储元数据，`.myi`文件存储索引数据。因为是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的，默认表锁，所以并发读也低。

InnoDB因其支持事务和行锁，并发性能高，在MySQL5.5被作为其默认的存储引擎。主键索引默认为聚集索引。InnoDB还支持`redo log`，对数据完整性也是可保障的（`crash-safe`）。

> 默认情况下，InnoDB存储引擎不会回滚超时引发的异常，除死锁外。

#### 2. 锁的分类

> 锁和触发器，其实都是基于索引实现的。都是为了实现快速筛选符合条件的数据行，而快速筛选，则是通过索引实现。

1. 记录锁（Record Locks）。（RD，RR）

   锁直接加在索引记录上面（无索引项时演变成**表锁**）。

2. 间隙锁（Gap Locks）。（RR）

   锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为可重复读或以上级别的。

3. 临间锁（Next-Key Locks）。（RR）

   对记录锁和间隙锁的组合，既锁住行也锁住间隙。并且采用的左开右闭`(x, y]`的原则，InnoDB 对于查询都是采用这种锁的。其解决了**幻读**。

4. 表锁。

   表锁就是将一整张表加锁，在表被锁定期间，其他事务不能对该表进行更新操作，必须等当前表的锁被释放后才能进行操作。

#### 3. MVCC和Read View

> MVCC多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于读已提交和可重复读取隔离级别的实现。因为，未提交读，永远拿到的都是表中最新的数据，这个快照也就没有意义。而串行化，所有的事务，串行执行，不存在并发访问数据，所以也就不需要这个快照。
>
> Read VIew可以理解为数据在某一时刻的一份内存快照，MVCC维护了多个Read View，而每个事务只对应一个Read View。

它是通过保存数据在某个时间点的快照来实现，这意味着一个事务在开始和结束看到的数据是相同的，不同事务看到的数据可能是不同的。保证了事务的**隔离性**。**MVCC是通过在每行记录后面保存两个隐藏的列来实现的。一个是事务id（trx_id），一个是回滚指针（roll_pointer）。**在每个事务开始时，会生成一个全局自增的一个事务id，修改某行记录时，都会把该事务的事务id赋值给`trx_id`隐藏列，把`undo`日志地址赋值给`roll_pointer`隐藏列。

由于每次变动都会先把`undo`日志记录下来，并用`roll_pointer`指向`undo`日志地址。因此可以认为，**对该条记录的修改日志串联起来就形成了一个`版本链`，版本链的头节点就是当前记录最新的值**。

什么是快照度和当前读。

> 快照度，读取MVCC中的数据，多个事务中读取的数据可能存在不一致。`select`默认加读取快照中的数据。
>
> 当前读，对于更新操作，默认采用当前读取，即读取表中的当前数据。多个事务并发操作只会有一个事务更新成功，其他事务会阻塞。（被修改的行被加排它锁，具体是行锁还是表锁，根据where条件来确定。更新超时数据不会回滚）

什么时候创建Read View。

> RR级别下，事务中的第一个SELECT请求才开始创建read view；
> RC级别下，事务中每次SELECT请求都会重新创建read view；

#### 4. 一条update语句的执行过程

##### 1. 执行流程

> 单条更新语句的执行，Innodb默认会以事务方式执行。

![image-20210624180642664](https://github.com/puyongqqq/blog/blob/master/assert/static/image-20210624180642664.png)

1. 连接数据库，清空查询缓存（MySQL8.0之前）；
2. 分析词法和语法后知道这是一条update语句，优化器决定使用ID这个索引执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行；
3. 如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器，否则，需要先从磁盘读入内存，然后再返回；
4. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据；
5. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务；
6. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘；
7. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

##### 2. 二阶段提交（2PC）

> 定义：更新流程中写入redo log的过程拆成了两个步骤prepare和commit。如果不使用两阶段提交，数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。

作用：**让redo log和binlog逻辑上保持一致。如果在commit时崩溃了，虽然没有commit，但是prepare和binlog完整，所以重启之后会自动commit。**

MySQL异常重启后的**崩溃恢复规则**:

1. 如果redo log里面的事务是完整的，也就是有了**commit标识**，则直接提交；

2. 如果redo log里面的事务只有完整的prepare，则判断对应的事务**是否存在完整的binlog**，如果是，则提交事务，否则，回滚事务。

redo log和binlog的如何关联。

它们有一个共同的数据字段**XID**，崩溃恢复的时候，会按顺序扫描redo log

如果碰到既有prepare, 又有commit的redo log, 就直接提交

如果碰到只有prepare, 而没有commit的redo log, 就拿着**XID去binlog找对应的事务**

redo log的innodb_flush_log_at_trx_commit参数配置

设置为0时：每秒写（os buffer），每秒刷（disk）。可能会丢失一秒的数据（宕机时）

设置为1时：实时写，实时刷。io性能差，但不会丢数据

设置为2时：实时写，每秒刷。可能会丢失一秒的数据

**双1配置**保证不丢数据：

innodb_flush_log_at_trx_commit=1 每次事务的redo log都直接持久化到磁盘。可以保证MySQL异常重启之后数据不丢失。

sync_binlog=1 每次事务的binlog都持久化到磁盘。可以保证MySQL异常重启之后binlog不丢失。

> xid是mysql server层维护的，通过一个全局变量 **global_query_id来生成，trx_id是innodb内部维护的**

#### 5. 几种日志的关系及作用

##### 	1. Redo log（重做日志）
模拟事务操作，记录事务修改操作。属于**物理日志**。不论事务是否提交，都会把对数据库的所有修改都记录下来，在MySQL服务异常重启之后，不会丢失数据。redo log包括两部分：一是内存中的**日志缓冲**(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。

在一条更新语句执行时，InnoDB默认采用**WAL + 2PC**，先记录Redo log日志，再更新内存中的数据。

属于InnoDB层面的日志，文件大小固定，采用循环写。记录的是**物理数据页修改的信息**，比如“某个数据页上内容发生了哪些改动”。

##### 	2. Undo log（回滚日志）
记录数据开始前，数据的原始信息。属于**逻辑日志**。它记录的是更新操作的**反向操作**。

##### 	3. Bin log（归档日志）
用做数据归档。日志通常有三种格式，Row，Statment，Mixed。主从复制基于此实现。

##### 	4. Slow log（慢日志）
分析SQL执行慢的问题。

MySQL运行慢，可能的情况有哪些？

1. 网络带宽小、抖动、机器内存小。升级硬件设备。
2. 数据量大。查看是否使用到索引，是否用到了索引覆盖，是否必要返回全部数据行（全部字段），可以尝试分页返回。
3. 锁。查看是否出现了死锁，排它锁。通常有MVCC不会存在。但是加写锁，仍然会被阻塞。
4. 刷盘。频繁的更新，可能出现偶尔的波动，建议加大内存，或者尝试修改刷盘的比例限制。

#### 6. Buffer Pool

由于磁盘随机读写的效率很低，MySQL为了提供性能，读写不是直接操作的磁盘文件，而是在内存中开辟了一个叫做Buffer pool的缓存区域，更新数据的时候会优先更新到Buffer pool，之后再由I/O线程写入磁盘。同时为了InnoDB为了保证宕机不丢失Buffer pool中的数据，实现crash safe，还引入了一个叫做redo log的日志模块。另外还有处于MySQL Server层的用于备份磁盘数据的bin log，用于事务回滚和MVCC的undo log等。

Buffer Pool Instance是MySQL缓冲池（Buffer Pool）的一个具体实例，通常在服务器内存小于1G时，只会创建一个实例。每个都有自己的锁，信号量，物理块(Buffer chunks)以及逻辑链表(List)。即各个instance之间没有竞争关系，可以并发读取与写入。所有instance的物理块(Buffer chunks)在数据库启动的时候被分配，直到数据库关闭内存才予以释放。

缓冲池中的数据按页`Page`存取，一页大小默认16K。主要存储**索引页**、**数据页**、**undo页**、**插入缓冲**（insert buffer)、**自适应哈希索引**（adaptive hash index)、**InnoDB存储的锁信息**（lock info)、**数据字典信息**（data dictionary)等。Buffer Pool 是按照Page大小来分配，受innodb_page_size控制。

##### 1. 三种Page

1. Free Page（**空闲页**）

   此Page 未被使用，位于 Free 链表

2. Clean Page（**干净页**）

   此Page 已被使用，但是页面未发生修改，位于LRU 链表。

3. Dirty Page（**脏页**）

   此Page 已被使用，页面已经被修改，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该Page 就变成了干净页。脏页 同时存在于LRU 链表和Flush 链表。

##### 2. 三种链表
1. LRU 链表

   采用**LRU算法**思想，**最近最少使用**的会被淘汰。链表被分成**两部分**，一部分是**New Sublist(Young 链表)**，用来存放**热数据**，默认占**5/8**，另外一部分是**Old Sublist(Old 链表)**，用来存放第一次进入LRU或者从热数据区域淘汰的页面，默认占**3/8**。**热数据区域的尾结点链接冷数据的头结点**。主要是为了预读的数据页和全表扫描污染Buffer pool。

   频繁访问一个Buffer Pool的页面，会促使页面往Young链表的头部移动。如果一个Page在被读到Buffer Pool后很快就被访问，那么该Page会往Young List的头部移动，但是如果一个页面是通过预读的方式读到Buffer Pool，且之后短时间内没有被访问，那么很可能在下次访问之前就被移动到Old List的尾部，而被驱逐了。

   > 优化点：
   >
   > 如果一个数据页已经处于Young 链表，当它再次被访问的时候，只有当其处于Young 链表长度的1/4(大约值)之后，才会被移动到Young 链表的头部。避免在热数据区域页面频繁调整在链表中的位置。

2. Flush 链表

   Flush 链表里面保存的都是**脏页**，这些脏页也会存在于LRU 链表。如果当前页面已经是脏页，就不需要再次加入Flush list，否则是第一次修改，需要加入Flush 链表。当Page Cleaner线程执行flush操作的时候，从尾部开始scan，将一定的脏页写入磁盘，推进检查点，减少recover的时间。

3. Free 链表

   Free 链表 存放的是**空闲页面**，初始化的时候申请一定数量的页面。

   在执行SQL的过程中，每次成功load 页面到内存后，会判断Free 链表的页面是否够用。如果不够用的话，就flush LRU 链表和Flush 链表来释放空闲页。如果够用，就从Free 链表里面删除对应的页面，在LRU 链表增加页面，保持总数不变。

   > 疑问：如果数据在缓冲区放不下时，会发生什么？

缓冲预读。

MySQL在读取数据的时候，会将查询到的数据按物理页取出，并将其加入到LRU List中。他还会异步的将后续的页面也读取到LRU List中。

预读失效。

由于预读(Read-Ahead)，提前把页放入了缓冲池，但最终MySQL并没有从页中读取数据，称为预读失效。

解决：

（1）将LRU分为两个部分：

- 新生代(new sublist)
- 老生代(old sublist)

（2）新老生代收尾相连，即：新生代的尾(tail)连接着老生代的头(head)；

（3）新页（例如被预读的页）加入缓冲池时，只加入到老生代头部：

- 如果数据真正被读取（预读成功），才会加入到新生代的头部
- 如果数据没有被读取，则会比新生代里的“热数据页”更早被淘汰出缓冲池

缓冲污染。

当某一个SQL语句，要批量扫描大量数据时，可能导致把缓冲池的所有页都替换出去，导致大量热数据被换出，MySQL性能急剧下降，这种情况叫缓冲池污染。

解决：

MySQL缓冲池加入了一个“**老生代停留时间窗口**”的机制：

- 假设T=老生代停留时间窗口；
- 插入老生代头部的页，即使立刻被访问，并不会立刻放入新生代头部；
- 只有**满足**“被访问”并且“在老生代停留时间”大于T，才会被放入新生代头部；

##### 3. 数据页访问机制

1. **当访问的页面在缓存池中命中，则直接从缓冲池中访问该页面**。另外为了避免查询数据页时扫描LRU，还为每个buffer pool instance维护了一个**page hash**，通过space id和page no可以直接找到对应的page。一般情况下，当我们需要读入一个Page时，首先根据space id和page no找到对应的buffer pool instance。然后查询page hash，如果page hash中没有，则表示需要从磁盘读取。
2. 如果没有命中，则需要将这个页面**从磁盘上加载到缓存池中**，因此需要在缓存池中的空闲列表中找一个空闲的内存块来缓存这个从磁盘读入的页面。
3. 但存在空闲内存块被使用完的情况，不保证一定有空闲的内存块。假如空闲列表为空，没有空闲的内存块，则需要想办法去产生空闲的内存块。
4. **首先去LRU列表中找可以替换的内存页面**，查找方向是从列表的**尾部**开始找，如果找到可以替换的页面，将其**从LRU列表中摘除，加入空闲列表**，然后再去空闲列表中找空闲的内存块。第一次查找最多只扫描100个页面，循环进行到第二次时，会查找深度就是整个LRU列表。这就是LRU列表中的页面淘汰机制。
5. 如果在LRU列表中没有找到可以替换的页，则进行**单页刷新**，将脏页刷新到磁盘之后，然后将释放的内存块加入到空闲列表。然后再去空闲列表中取。为什么只做单页刷新呢？因为这个函数的目的是获取空闲内存页，进行脏页刷新是不得已而为之，所以只会进行一个页面的刷新，目的是为了尽快的获取空闲内存块。

##### 4. 脏页刷盘时机

1. **REDO日志快用满的时候**。由于MySQL更新是先写REDO日志，后面再将数据Flush到磁盘，如果REDO日志对应脏数据还没有刷新到磁盘就被覆盖的话，万一发生Crash，数据就无法恢复了。此时会从Flush 链表里面选取脏页，进行Flush。
2. **页面加载到缓冲池时**。Page Cleaner线程会从LRU 链表尾部淘汰一部分页面作为空闲页。如果对应的页面是脏页的话，就需要先将页面Flush到磁盘。
3. **MySQL中脏页太多的时候**。当最大脏页比例超过阈值（默认75%）时，会触发强制刷脏页，从而保证系统有足够可用的Free Page。
4. **MySQL实例正常关闭时**。关闭时需要把缓冲区中的数据持久化到磁盘。

> Innodb 的三种Page和链表的设计，保证了我们需要的热数据常驻在内存，及时淘汰不需要的数据，提升了我们的查询速度，同时不同的刷脏策略也提高了我们的恢复速度，保证了数据安全。

#### 7. 索引失效场景

1. 破坏最左原则。
   1. like 运用不当。（B+树索引存储导致）
   2. or 的字段如果不存在索引。（全部字段加上索引可解）
   3. 复合索引未用左列字段。（B+树索引存储导致）
   4. IS NULL /IS NOT NULL
   5. <>
2. 使用函数计算。 
   1. 隐式转换。
   2. where中索引列有运算或者函数运算。
3. 存储引擎的选择。存储引擎认为全表比走索引快。

#### 8. 主备延迟问题及解决

数据同步采用半同步复制。

1. 在master上提交事务后，并且写入binlog，返回事务成功标记；
2. 将binlog发送到slave，转储成relay log；
3. 在slave上再将relay log读取出来应用。

为保证强一致性，从库复制完成之后，主库才返回写成功。

如何保证主从数据一致性？

1. 主库启用**双1配置**

   ```sql
   # rodolog 配置
   innodb_flush_log_at_trx_commit = 1
   # undo log 配置
   sync_binlog = 1
   ```

2. 从库复制配置

   ```sql
   # 保证在slave上和复制相关的元数据表也采用InnoDB引擎，受到InnoDB事务安全的保护
   master_info_repository = "TABLE"
   relay_log_info_repository = "TABLE"
   # 开启relay log自动修复机制，发生crash时，会自动判断哪些relay log需要重新从master上抓取回来再次应用，以此避免部分数据丢失的可能性
   relay_log_recovery = 1
   ```

3. 最终一致性

   如果同上上述两条配置仍然出现数据不一致，可通过`pt-table-checksum`和`pt-table-sync`工具介入。

如何判断发生了复制延迟。

- 主节点更改数据后，主节点保存到二进制日志文件需要花时间。
- 从节点的I/O进程拉取二进制日志文件，并将其保存在从节点的中继日志文件中需要时间。
- 从节点的SQL进程对中继日志进行读取、解析、执行也需要花时间。
- 主节点的并发请求较高时，产生的DDL数量超过从节点一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与从节点的大型query语句产生了锁等待。

如何解决复制延迟。

1. 增加**缓存**，Redis，Cache。
2. 建议**从库数量3-5个为宜**，如果一个主节点的从节点过多，要复制的从节点数量就多，就会增加复制延迟时间。
3. 采用**多线程复制**方式。当然只有高版本mysql才支持多线程复制，主从复制单线程，如果主节点写操作并发太大，来不及传送到从节点就会导致延迟。
4. 升级硬件。



## 参考链接

1. <a target="_blank" href="https://zhuanlan.zhihu.com/p/102802249">Innodb Buffer Pool的三种Page和链表</a>
2. <a target="_blank" href="https://zhuanlan.zhihu.com/p/65811829">[玩转MySQL之十]InnoDB Buffer Pool详解</a>
3. <a target="_blank" href="https://time.geekbang.org/column/intro/100020801">MySQL实战45讲</a>
4. <a target="_blank" href="https://zhuanlan.zhihu.com/p/110503812">MySQL主从复制导致从节点延迟问题</a>

